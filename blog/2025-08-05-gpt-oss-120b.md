---
title: "Deploying OpenAI's GPT-OSS on 8 H100 GPUs with Sinked Sliding Window Attention"
author: "Eigen AI, SGLang and Yotta Labs"
date: "Aug 05 2025"
previewImg: "/images/blog/2025-08-05-gpt-oss-120b/gpt-oss-architecture.png"
---

Eigen AI and SGLang teams are excited to share early results from running GPT-OSS-120B on H100. With BF16 quantization precision, we achieve 31,615 output tokens/s per node for decoding on a single H100 node. 
