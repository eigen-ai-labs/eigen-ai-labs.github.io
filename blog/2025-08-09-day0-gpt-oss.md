---
title: "Day 0 Support of Serving OpenAI GPT-OSS on Hopper and Blackwell GPUs with Free Online Playground"
author: "Eigen AI Team"
date: "Aug 09 2025"
previewImg: "/images/blog/2025-08-09-day0-gpt-oss/arch.png"
---

In this blog, we're excited to achieve day 0 support for the serving of OpenAI’s GPT-OSS-120B and GPT-OSS-20B on Hopper/Blackwell GPUs in collaboration with the SGLang team. We also introduce a free online playground featuring both web and API access to the GPT-OSS-120B model ([chat.eigenai.com](https://chat.eigenai.com)) in partnership with Yotta Labs. Major performance optimizations are already in the pipeline, and we expect to offer even faster, smarter, and more scalable services in the days ahead.

---

## Introduction of GPT-OSS Architecture

GPT-OSS is a newly released open-source large language model (LLM) from OpenAI designed for the efficient deployment of reasoning tasks. OpenAI open-sourced two versions of GPT-OSS: [GPT-OSS-120B and GPT-OSS-20B](https://huggingface.co/openai/gpt-oss-20b/blob/main/README.md).

- **GPT-OSS-120B**: for production, general purpose, high reasoning use cases (117B parameters)  
- **GPT-OSS-20B**: for lower latency, and local or specialized use cases (21B parameters)  

Figure 1 illustrates the architectural details.

![GPT-OSS Architecture](/images/blog/2025-08-09-day0-gpt-oss/arch.png)

**Figure 1.** Illustration of GPT-OSS architecture. GptOssMoE layers and GptOssAttn (sinked sliding window grouped-query attention) layers.

---

### GptOssAttn

GPT-OSS introduces a novel attention mechanism that interleaves sliding window attention and full attention. Specifically, odd-numbered layers use sliding window grouped-query attention (GQA) with a window size of 128, and even layers use full attention. All attention layers include bias terms in the linear projection layers (queries, keys, values, and output). A distinctive sinked attention mechanism is applied: for each attention head, a learnable scalar parameter (referred to as the sink) is appended as the last column of the attention score matrix **S** prior to softmax. After softmax computation, the sink column is detached, yielding a standard square attention matrix **A**. This operation is mathematically equivalent to modifying the softmax denominator with an additional exponential term:

![Attention Sink Mechanism](/images/blog/2025-08-09-day0-gpt-oss/eqn1.png)

---

### GptOssMoE

For Mixture-of-Experts (MoE) layers, each token selects the top-4 experts based on router scores from 128 (for 120B) or 32 (for 20B) experts. The expert adopts **SwigLU** activation, and three linear layers, including gate, up, and down projections, all have bias terms enabled. The gate branch employs a **Swish** activation function with β = 1.702, and the up branch is added by 1 and multiplied with the gate output. To ensure numerical stability:

- The gate pre-activation is clipped at a maximum value of 7 before applying Swish.  
- The up branch is clipped to the range [−7, 7] before the +1 shift.

The MoE computation is summarized as:

![MoE Computation](/images/blog/2025-08-09-day0-gpt-oss/eqn2.png)

The outputs of the top-k selected experts will be summed up with the softmax-normalized router weights.

![MoE Output](/images/blog/2025-08-09-day0-gpt-oss/eqn3.png)

---

## Try Local GPT-OSS Serving on Hopper/Blackwell GPUs

Please follow the instructions [here](https://github.com/sgl-project/sglang/issues/8833) to set up a ready-to-use container to try out GPT-OSS serving.

---

## Introducing the Eigen AI Playground

We’re thrilled to announce the launch of the **Eigen AI Playground**, built in partnership with Yotta Labs – a free online platform where anyone can experience the power of OpenAI’s GPT-OSS-120B model right in their browser: [chat.eigenai.com](https://chat.eigenai.com). This platform is well optimized for performance and includes comprehensive, reproducible deployment guides, enabling users to integrate these advancements into their projects with ease. This initiative reflects our broader vision to make the transformative power of AI accessible globally, fostering innovation across industries and communities.

**Explore now on the web:**

The web interface offers an intuitive and smooth chat experience with GPT-OSS-120B:  

![Web Playground](/images/blog/2025-08-09-day0-gpt-oss/chatbot.png)

**Integrate via API:**

For developers or advanced users, we also provide a simple API that allows you to integrate GPT-OSS-120B directly into your applications for free.

```python
# First install: pip install openai

import openai

client = openai.OpenAI(
    api_key="xxx",
    base_url="https://gateway.eigenai.com/inference/public/v1"
)

response = client.chat.completions.create(
    model="OpenAI/GPT-OSS-120B",
    messages=[
        {"role": "assistant", "content": "what can i help you?"},
        {"role": "user", "content": "test"},
    ],
    temperature=0.6,
    max_tokens=8192,
    stream=False,
)

# Print the completion result
print(response.choices[0].message.content)
```

---

## Further Reading

- [At Eigen AI, we’re on a mission to make sure the AI revolution doesn’t leave anyone behind. | Eigen AI](https://x.com/Eigen_AI_Labs/status/1952931721655292056)  
- [SGLang GitHub Repository](https://github.com/sgl-project/sglang)  
- [EigenAI Labs Huggingface Repository with GPT-OSS BF16 Checkpoints](https://huggingface.co/eigen-ai-labs/gpt-oss-120b-bf16)  
